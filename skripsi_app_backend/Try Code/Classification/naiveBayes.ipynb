{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_r1</th>\n",
       "      <th>hist_r2</th>\n",
       "      <th>hist_r3</th>\n",
       "      <th>hist_r4</th>\n",
       "      <th>hist_r5</th>\n",
       "      <th>hist_r6</th>\n",
       "      <th>hist_r7</th>\n",
       "      <th>hist_r8</th>\n",
       "      <th>hist_r9</th>\n",
       "      <th>hist_r10</th>\n",
       "      <th>...</th>\n",
       "      <th>correlation 135</th>\n",
       "      <th>homogeneity 0</th>\n",
       "      <th>homogeneity 45</th>\n",
       "      <th>homogeneity 90</th>\n",
       "      <th>homogeneity 135</th>\n",
       "      <th>contrast 0</th>\n",
       "      <th>contrast 45</th>\n",
       "      <th>contrast 90</th>\n",
       "      <th>contrast 135</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.039038</td>\n",
       "      <td>0.207669</td>\n",
       "      <td>0.146596</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>0.029648</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>...</td>\n",
       "      <td>8.605303e-07</td>\n",
       "      <td>4.192673e-07</td>\n",
       "      <td>4.150844e-07</td>\n",
       "      <td>4.197719e-07</td>\n",
       "      <td>4.156177e-07</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.271105</td>\n",
       "      <td>0.212197</td>\n",
       "      <td>0.050067</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>...</td>\n",
       "      <td>8.691078e-07</td>\n",
       "      <td>4.452269e-07</td>\n",
       "      <td>4.452233e-07</td>\n",
       "      <td>4.507729e-07</td>\n",
       "      <td>4.366966e-07</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103315</td>\n",
       "      <td>0.199026</td>\n",
       "      <td>0.174257</td>\n",
       "      <td>0.080620</td>\n",
       "      <td>0.039155</td>\n",
       "      <td>0.019731</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>9.019347e-07</td>\n",
       "      <td>4.103746e-07</td>\n",
       "      <td>4.019372e-07</td>\n",
       "      <td>4.081924e-07</td>\n",
       "      <td>4.075827e-07</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103222</td>\n",
       "      <td>0.198996</td>\n",
       "      <td>0.174423</td>\n",
       "      <td>0.080561</td>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>...</td>\n",
       "      <td>9.007762e-07</td>\n",
       "      <td>4.081871e-07</td>\n",
       "      <td>4.074348e-07</td>\n",
       "      <td>4.103747e-07</td>\n",
       "      <td>4.017191e-07</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116474</td>\n",
       "      <td>0.208589</td>\n",
       "      <td>0.178227</td>\n",
       "      <td>0.086086</td>\n",
       "      <td>0.042961</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>...</td>\n",
       "      <td>9.155645e-07</td>\n",
       "      <td>3.978208e-07</td>\n",
       "      <td>3.904608e-07</td>\n",
       "      <td>3.914334e-07</td>\n",
       "      <td>3.899064e-07</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.113938</td>\n",
       "      <td>0.178202</td>\n",
       "      <td>0.180940</td>\n",
       "      <td>0.127132</td>\n",
       "      <td>0.057202</td>\n",
       "      <td>0.015685</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>...</td>\n",
       "      <td>9.651308e-07</td>\n",
       "      <td>4.012872e-07</td>\n",
       "      <td>3.985030e-07</td>\n",
       "      <td>4.013542e-07</td>\n",
       "      <td>3.985742e-07</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>0.132912</td>\n",
       "      <td>0.154670</td>\n",
       "      <td>0.166026</td>\n",
       "      <td>0.130787</td>\n",
       "      <td>0.058650</td>\n",
       "      <td>0.014018</td>\n",
       "      <td>...</td>\n",
       "      <td>9.905691e-07</td>\n",
       "      <td>4.251076e-07</td>\n",
       "      <td>4.209643e-07</td>\n",
       "      <td>4.234953e-07</td>\n",
       "      <td>4.203639e-07</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.127529</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.161088</td>\n",
       "      <td>0.088621</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.026463</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>...</td>\n",
       "      <td>9.433900e-07</td>\n",
       "      <td>4.061770e-07</td>\n",
       "      <td>4.024677e-07</td>\n",
       "      <td>4.091041e-07</td>\n",
       "      <td>4.043544e-07</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.106331</td>\n",
       "      <td>0.198495</td>\n",
       "      <td>0.142571</td>\n",
       "      <td>0.078099</td>\n",
       "      <td>0.049343</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>9.038719e-07</td>\n",
       "      <td>4.378636e-07</td>\n",
       "      <td>4.312089e-07</td>\n",
       "      <td>4.359519e-07</td>\n",
       "      <td>4.323478e-07</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.106262</td>\n",
       "      <td>0.198183</td>\n",
       "      <td>0.142967</td>\n",
       "      <td>0.078040</td>\n",
       "      <td>0.049368</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>...</td>\n",
       "      <td>9.028200e-07</td>\n",
       "      <td>4.358201e-07</td>\n",
       "      <td>4.324162e-07</td>\n",
       "      <td>4.377373e-07</td>\n",
       "      <td>4.309557e-07</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hist_r1   hist_r2   hist_r3   hist_r4   hist_r5   hist_r6   hist_r7  \\\n",
       "0    0.001646  0.039038  0.207669  0.146596  0.063886  0.035679  0.029648   \n",
       "1    0.015835  0.271105  0.212197  0.050067  0.018268  0.009250  0.005762   \n",
       "2    0.103315  0.199026  0.174257  0.080620  0.039155  0.019731  0.011954   \n",
       "3    0.103222  0.198996  0.174423  0.080561  0.039177  0.019845  0.011812   \n",
       "4    0.116474  0.208589  0.178227  0.086086  0.042961  0.021757  0.012858   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "795  0.000767  0.025029  0.113938  0.178202  0.180940  0.127132  0.057202   \n",
       "796  0.000003  0.000735  0.012757  0.061054  0.132912  0.154670  0.166026   \n",
       "797  0.005201  0.127529  0.225876  0.161088  0.088621  0.057062  0.026463   \n",
       "798  0.003396  0.106331  0.198495  0.142571  0.078099  0.049343  0.022459   \n",
       "799  0.003387  0.106262  0.198183  0.142967  0.078040  0.049368  0.022453   \n",
       "\n",
       "      hist_r8   hist_r9  hist_r10  ...  correlation 135  homogeneity 0  \\\n",
       "0    0.030528  0.024858  0.008947  ...     8.605303e-07   4.192673e-07   \n",
       "1    0.003873  0.002522  0.001520  ...     8.691078e-07   4.452269e-07   \n",
       "2    0.007497  0.004205  0.001967  ...     9.019347e-07   4.103746e-07   \n",
       "3    0.007533  0.004154  0.001996  ...     9.007762e-07   4.081871e-07   \n",
       "4    0.008022  0.004492  0.002145  ...     9.155645e-07   3.978208e-07   \n",
       "..        ...       ...       ...  ...              ...            ...   \n",
       "795  0.015685  0.004245  0.002074  ...     9.651308e-07   4.012872e-07   \n",
       "796  0.130787  0.058650  0.014018  ...     9.905691e-07   4.251076e-07   \n",
       "797  0.007203  0.002812  0.001569  ...     9.433900e-07   4.061770e-07   \n",
       "798  0.005612  0.002259  0.001335  ...     9.038719e-07   4.378636e-07   \n",
       "799  0.005628  0.002239  0.001346  ...     9.028200e-07   4.358201e-07   \n",
       "\n",
       "     homogeneity 45  homogeneity 90  homogeneity 135  contrast 0  contrast 45  \\\n",
       "0      4.150844e-07    4.197719e-07     4.156177e-07    0.000510     0.000549   \n",
       "1      4.452233e-07    4.507729e-07     4.366966e-07    0.000317     0.000380   \n",
       "2      4.019372e-07    4.081924e-07     4.075827e-07    0.000375     0.000465   \n",
       "3      4.074348e-07    4.103747e-07     4.017191e-07    0.000430     0.000443   \n",
       "4      3.904608e-07    3.914334e-07     3.899064e-07    0.000447     0.000514   \n",
       "..              ...             ...              ...         ...          ...   \n",
       "795    3.985030e-07    4.013542e-07     3.985742e-07    0.000561     0.000606   \n",
       "796    4.209643e-07    4.234953e-07     4.203639e-07    0.000513     0.000568   \n",
       "797    4.024677e-07    4.091041e-07     4.043544e-07    0.000570     0.000611   \n",
       "798    4.312089e-07    4.359519e-07     4.323478e-07    0.000447     0.000520   \n",
       "799    4.324162e-07    4.377373e-07     4.309557e-07    0.000446     0.000501   \n",
       "\n",
       "     contrast 90  contrast 135  Label  \n",
       "0       0.000485      0.000557      1  \n",
       "1       0.000341      0.000404      1  \n",
       "2       0.000430      0.000443      1  \n",
       "3       0.000375      0.000465      1  \n",
       "4       0.000480      0.000542      1  \n",
       "..           ...           ...    ...  \n",
       "795     0.000545      0.000598      5  \n",
       "796     0.000554      0.000592      5  \n",
       "797     0.000518      0.000612      5  \n",
       "798     0.000446      0.000501      5  \n",
       "799     0.000447      0.000520      5  \n",
       "\n",
       "[800 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../hasil_ekstraksi_rata2_rgb.csv\")\n",
    "df = pd.read_csv(\"../../Code/Classification/train_data2.csv\")\n",
    "# df = pd.read_csv(\"../hasil_ekstraksi_rata2RGB_glcm.csv\")\n",
    "# df = pd.read_csv(\"../hasil_ekstraksi_orde1_glcm1.csv\")\n",
    "# df = pd.read_csv(\"../hasil_ekstraksi_orde1_glcm.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Skripsi\\Build Apps\\skripsi_app_backend\\Try Code\\Classification\\naiveBayes.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Skripsi/Build%20Apps/skripsi_app_backend/Try%20Code/Classification/naiveBayes.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Skripsi/Build%20Apps/skripsi_app_backend/Try%20Code/Classification/naiveBayes.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Skripsi/Build%20Apps/skripsi_app_backend/Try%20Code/Classification/naiveBayes.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   4955\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   4956\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4957\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   4958\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   4959\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   4960\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   4961\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   4962\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4269\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=\"label\")\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# scaler.fit(X_train)\n",
    "\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-60 {color: black;background-color: white;}#sk-container-id-60 pre{padding: 0;}#sk-container-id-60 div.sk-toggleable {background-color: white;}#sk-container-id-60 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-60 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-60 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-60 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-60 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-60 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-60 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-60 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-60 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-60 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-60 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-60 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-60 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-60 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-60 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-60 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-60 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-60 div.sk-item {position: relative;z-index: 1;}#sk-container-id-60 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-60 div.sk-item::before, #sk-container-id-60 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-60 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-60 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-60 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-60 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-60 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-60 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-60 div.sk-label-container {text-align: center;}#sk-container-id-60 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-60 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-60\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" checked><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.67      0.80         6\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       0.69      0.69      0.69        13\n",
      "           4       0.36      0.44      0.40         9\n",
      "           5       0.44      0.44      0.44         9\n",
      "\n",
      "    accuracy                           0.64        44\n",
      "   macro avg       0.70      0.65      0.67        44\n",
      "weighted avg       0.67      0.64      0.65        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# menghitung confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "366a4f848469d28a32ae9de383029dd12ac0cf9e43f1d301e9bcc00748ebef1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
